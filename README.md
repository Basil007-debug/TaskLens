 # 📝 TaskLens

## 🚀 Overview
Task Evaluation Home is a **web-based AI-powered tool** that automates the evaluation of tasks assigned to individuals, particularly junior team members. The system leverages **Large Language Models (LLMs)** to assess task submissions, including **code files (PDF format) and text descriptions**. It generates detailed feedback and **automated email notifications** to streamline task management and performance tracking.

## ✨ Features
✅ **Automated Task Evaluation** – Uses LLMs to analyze code and text submissions.  
✅ **Detailed Feedback & Reports** – Generates PDF reports with performance insights and improvement suggestions.  
✅ **Email Notifications** – Automatically sends evaluation reports to users.  
✅ **User-friendly Interface** – Simple and interactive **Streamlit UI** for easy task uploads and result viewing.  

## 🛠️ Tech Stack
- **Backend:** Python (Flask/FastAPI for API, pandas, PyPDF2, reportlab for data handling)
- **Frontend:** Streamlit (for an interactive and dynamic UI)
- **AI & LLM Integration:** Langchain + Groq API (for task evaluation and feedback generation)

## 🔄 Workflow
1. **User Submission** – Upload code (PDF) or text tasks via the **Streamlit UI**.  
2. **Data Processing** – Extract and clean task content.  
3. **LLM Analysis** – Use **Langchain + Groq API** to evaluate and generate feedback.  
4. **Report Generation** – Compile insights into a structured PDF.  
5. **Email Delivery** – Automatically send results to the user.  


## 🎯 Project Goals
📌 **Automate** task evaluation for efficiency.  
📌 **Enhance** feedback quality with AI insights.  
📌 **Streamline** user experience with an intuitive UI.  
📌 **Ensure** continuous improvement with a feedback loop.  



## 🤝 Contributing
Contributions are welcome! Feel free to fork the repo, submit issues, or open pull requests. 🚀

## 📜 License
This project is licensed under the **MIT License**.

## 📬 Contact
For inquiries, reach out to **Basil Tamil Selvan E**.

